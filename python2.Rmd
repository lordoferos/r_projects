---
title: "Python 2"
author: "Levi Orero"
date: "5/2/2020"
output: html_document
---

```{python}
#Test datasets
import pandas as pd
diabetes = pd.read_csv('C://Users/LORERO/OneDrive - CGIAR/Documents/diabetes.csv')
```

```{python}
#Check dimensions
diabetes.shape

#Check sample
diabetes.head(3)
```

```{python}
print(diabetes.columns)
```

```{python}
#Describe data similar to summary
diabetes.describe()
```
```{python}
#Create a sub data frame
age = diabetes[["Age","Glucose"]]
age
```

```{r}
library(reticulate)
matplotlib <- import("matplotlib", convert = TRUE)
matplotlib$use("Agg", force = TRUE) 
library(knitr)
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
```

# Plotting and Visualization
```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
diabetes = pd.read_csv('C://Users/LORERO/OneDrive - CGIAR/Documents/diabetes.csv')
diabetes.groupby('Outcome').hist(figsize = (9,9))
plt.show()
```

Simple boxplot can be created by simply using the “by=” parameter inside the boxplot function for the dataframe (data). The “Outcome” data either positive=1 and negative=0. In this case, “Age” is grouped by the “Outcome”. This is a boxplot of all the Ages of people who have either Outcome=0 or Outcome=1.
```{python}
diabetes.boxplot(column = ['Age'], by = ['Outcome'])
plt.show()
```


# Missing Data Handling
```{python}
diabetes.isnull().sum()
diabetes.isna().sum()
```

# Linear Regression
Linear regression is a great example to start to see the power of sklearn. This package contains all the models needed for scientific computing.
Instead of using the diabetes dataset that grabbed earlier, we can use the same dataset imported inside sklearn.

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score

diabetes = datasets.load_diabetes()

diabetes_X = diabetes.data[:, np.newaxis, 2]
```

## Split the data into training/testing sets
```{python}
diabetes_X_train = diabetes_X[:-20]
diabetes_X_test = diabetes_X[-20:]
```

## Split the targets into training/testing sets
```{python}
diabetes_y_train = diabetes.target[:-20]
diabetes_y_test = diabetes.target[-20:]
```

## Create a linear regression object
```{python}
regr = linear_model.LinearRegression()
```

## Train the model using the training sets
```{python}
regr.fit(diabetes_X_train, diabetes_y_train)
```

## Make predictions using the training sets
```{python}
diabetes_y_pred = regr.predict(diabetes_X_test)
```

## The Coefficients
```{python}
print('Coefficients: \n', regr.coef_)
```
## The Mean Squared Error
```{python}
print("Mean squared error: %.2f"%mean_squared_error(diabetes_y_test,
diabetes_y_pred))
```
## Explained variance score: 1 is perfect prediction
```{python}
print('Variance score: %.2f' % r2_score(diabetes_y_test,diabetes_y_pred))
```

## Plot outputs
```{python}
plt.scatter(diabetes_X_test, diabetes_y_test, color = 'black')

plt.plot(diabetes_X_test, diabetes_y_pred, color = 'blue', linewidth=3)

plt.xticks(())
plt.yticks(())

plt.show()
```

